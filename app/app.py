# app/app.py

import gradio as gr
import time

# Import c√°c h√†m x·ª≠ l√Ω t·ª´ th∆∞ m·ª•c src
from src.data_processor import load_documents, chunk_documents
from src.vector_store_manager import create_vector_store
from src.pipeline import create_llm, create_qa_chain, answer_question

# Kh·ªüi t·∫°o LLM ngay khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian
llm = create_llm()


def process_file(file):
    if file is None:
        return None, "Vui l√≤ng t·∫£i l√™n m·ªôt file."

    file_path = file.name
    print(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {file_path}")

    try:
        docs = load_documents(file_path)
        if not docs:
            return None, f"Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ file {file.name}."

        chunks = chunk_documents(docs)
        if not chunks:
            return None, "T√†i li·ªáu qu√° ng·∫Øn ƒë·ªÉ c√≥ th·ªÉ ph√¢n ƒëo·∫°n."

        vector_store = create_vector_store(chunks)
        print("ƒê√£ x·ª≠ l√Ω file th√†nh c√¥ng!")
        return vector_store, f"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng file: {file.name}"
    except Exception as e:
        return None, f"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω file: {e}"


def chat_with_document(question, history, vector_store):
    if vector_store is None:
        history.append((question, "L·ªói: Vui l√≤ng t·∫£i l√™n v√† nh·∫•n 'X·ª≠ l√Ω' m·ªôt t√†i li·ªáu tr∆∞·ªõc."))
        return history

    # T·∫°o chu·ªói QA v·ªõi LLM ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
    qa_chain = create_qa_chain(vector_store, llm)

    # L·∫•y c√¢u tr·∫£ l·ªùi
    result = answer_question(qa_chain, question)
    answer = result.get("result", "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi.")
    history.append((question, answer))
    return history


with gr.Blocks() as demo:
    vector_store_state = gr.State(None)

    gr.Markdown("# üí¨ H·ªèi ƒê√°p T√†i Li·ªáu C·ªßa B·∫°n (RAG Demo)")
    gr.Markdown("T·∫£i l√™n file .PDF ho·∫∑c .TXT c·ªßa b·∫°n, nh·∫•n 'X·ª≠ l√Ω', sau ƒë√≥ ƒë·∫∑t c√¢u h·ªèi v·ªÅ n·ªôi dung b√™n trong.")

    with gr.Row():
        with gr.Column(scale=3):
            file_uploader = gr.File(label="T·∫£i t√†i li·ªáu l√™n", file_types=['.pdf', '.txt'])
            process_button = gr.Button("X·ª≠ l√Ω", variant="primary")
            status_display = gr.Textbox(label="Tr·∫°ng th√°i x·ª≠ l√Ω", interactive=False)

        with gr.Column(scale=7):
            chatbot = gr.Chatbot(label="Cu·ªôc h·ªôi tho·∫°i", bubble_full_width=False, value = [])
            msg = gr.Textbox(label="ƒê·∫∑t c√¢u h·ªèi c·ªßa b·∫°n ·ªü ƒë√¢y")
            clear = gr.ClearButton([msg, chatbot])

    # ƒê·ªãnh nghƒ©a lu·ªìng t∆∞∆°ng t√°c
    process_button.click(
        fn=process_file,
        inputs=[file_uploader],
        outputs=[vector_store_state, status_display],
        show_progress="full"
    )

    msg.submit(
        fn=chat_with_document,
        inputs=[msg, chatbot, vector_store_state],
        outputs=[chatbot],
    ).then(lambda: gr.update(value=""), outputs=[msg])

if __name__ == "__main__":
    demo.launch(debug=True)